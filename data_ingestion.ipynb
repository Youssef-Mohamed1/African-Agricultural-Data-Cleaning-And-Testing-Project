{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90c213e4",
   "metadata": {},
   "source": [
    "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/Python-Notebook-Banners/Code_challenge.png\"  style=\"display: block; margin-left: auto; margin-right: auto;\";/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f662d169",
   "metadata": {},
   "source": [
    "# Integrated project: Validating our data\n",
    "© ExploreAI Academy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26af890c",
   "metadata": {},
   "source": [
    "In this Code Challenge we’re diving into the agricultural dataset again to continue to validate our data. Before we do that, we’re pausing to build a data pipeline that will ingest and clean our data with the press of a button, cleaning up our code significantly. Once that’s ready, we’ll complete our data validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d133774e",
   "metadata": {},
   "source": [
    "⚠️ **NOTE that this code challenge is graded and will contribute to your overall marks for this module. Submit this notebook for grading. Note that the names of the functions are different in this notebook. Transfer the code in your notebook to this submission notebook**\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- **Do not add or remove cells in this notebook. Do not edit or remove the `### START FUNCTION` or `### END FUNCTION` comments. Do not add any code outside of the functions you are required to edit. Doing any of this will lead to a mark of 0%!**\n",
    "\n",
    "- Answer the questions according to the specifications provided.\n",
    "\n",
    "- Use the given cell in each question to see if your function matches the expected outputs.\n",
    "\n",
    "- Do not hard-code answers to the questions.\n",
    "\n",
    "- The use of StackOverflow, Google, and other online tools is permitted. However, copying a fellow student's code is not permissible and is considered a breach of the Honour code. Doing this will result in a mark of 0%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8944ccbc",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2e633f",
   "metadata": {},
   "source": [
    "Let's pick up where we left off, shall we?\n",
    "\n",
    "Recall our previous disappointment - the mismatch between our dataset and the weather station data? That was a curveball, wasn't it? Half of our measurements were out of range, raising eyebrows and doubts alike. Our quest for data validation had hit a snag, but as any seasoned data scientist will tell you, every problem is a hidden opportunity waiting to be discovered.\n",
    "\n",
    "I'm sure you have some ideas on how to solve this, so I'll share mine...\n",
    "\n",
    "One thing that bugs me is the tolerance level I chose. Why 1.5%? \n",
    "\n",
    "We saw that half of our means were not within that tolerance, but why would it be within 1.5% and not 5%?\n",
    "\n",
    "Although we may think 1.5% is a good measurement of accuracy, there may be errors in each dataset, and more variation in one than the other, which could make the means differ by more than 1.5% even if the objective truth is that the means are the same. We need to be a little more scientific with our approach and account for the difference in the data. I am sure you know what I am about to say next, right?\n",
    "\n",
    "**Hypothesis testing** takes into account both the means and the variances of the distributions being compared. The variance here is crucial because it gives us insight into the spread of the data points around the means for our two datasets. Two samples could have the same mean but very different variances, leading to different interpretations of their similarities or differences.\n",
    "\n",
    "Our main goal is the same: Is the data in our `MD_agric_df` dataset representative of reality? To answer this, we use weather-related data from nearby stations to validate our results. If the weather data matches the data we have, we can be more confident that our dataset represents reality. \n",
    "\n",
    "So what's the plan? \n",
    "1. Create a null hypothesis.\n",
    "1. Import the `MD_agric_df` dataset and clean it up.\n",
    "1. Import the weather data.\n",
    "1. Map the weather data to the field data.\n",
    "1. Calculate the means of the weather station dataset and the means of the main dataset.\n",
    "2. Calculate all the parameters we need to do a t-test. \n",
    "3. Interpret our results.\n",
    "\n",
    "Do you see a bit of repetition here? Steps 2-5 are a repeat of last time. The quick and dirty fix is to copy that code across to our notebook, but what about next time and the time after that? All of that code will also clutter this notebook and make our analysis harder to read.\n",
    "\n",
    "You might also think of exporting the fixed and merged data from last time to a CSV, but what if there is new data in the database?\n",
    "\n",
    "So, let's stop for a second and think about how we can make this simpler, more extendible and reusable in the future. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147be850",
   "metadata": {},
   "source": [
    "# Data dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe8e55e",
   "metadata": {},
   "source": [
    "**1. Geographic features**\n",
    "\n",
    "- **Field_ID:** A unique identifier for each field (BigInt).\n",
    " \n",
    "- **Elevation:** The elevation of the field above sea level in metres (Float).\n",
    "\n",
    "- **Latitude:** Geographical latitude of the field in degrees (Float).\n",
    "\n",
    "- **Longitude:** Geographical longitude of the field in degrees (Float).\n",
    "\n",
    "- **Location:** Province the field is in (Text).\n",
    "\n",
    "- **Slope:** The slope of the land in the field (Float).\n",
    "\n",
    "**2. Weather features**\n",
    "\n",
    "- **Field_ID:** Corresponding field identifier (BigInt).\n",
    "\n",
    "- **Rainfall:** Amount of rainfall in the area in mm (Float).\n",
    "\n",
    "- **Min_temperature_C:** Average minimum temperature recorded in Celsius (Float).\n",
    "\n",
    "- **Max_temperature_C:** Average maximum temperature recorded in Celsius (Float).\n",
    "\n",
    "- **Ave_temps:** Average temperature in Celcius (Float).\n",
    "\n",
    "**3. Soil and crop features**\n",
    "\n",
    "- **Field_ID:** Corresponding field identifier (BigInt).\n",
    "\n",
    "- **Soil_fertility:** A measure of soil fertility where 0 is infertile soil, and 1 is very fertile soil (Float).\n",
    "\n",
    "- **Soil_type:** Type of soil present in the field (Text).\n",
    "\n",
    "- **pH:** pH level of the soil, which is a measure of how acidic/basic the soil is (Float).\n",
    "\n",
    "**4. Farm management features**\n",
    "\n",
    "- **Field_ID:** Corresponding field identifier (BigInt).\n",
    "\n",
    "- **Pollution_level:** Level of pollution in the area where 0 is unpolluted and 1 is very polluted (Float).\n",
    "\n",
    "- **Plot_size:** Size of the plot in the field (Ha) (Float).\n",
    "\n",
    "- **Chosen_crop:** Type of crop chosen for cultivation (Text).\n",
    "\n",
    "- **Annual_yield:** Annual yield from the field (Float). This is the total output of the field. The field size and type of crop will affect the Annual Yield\n",
    "\n",
    "- **Standard_yield:** Standardised yield expected from the field, normalised per crop (Float). This is independent of field size, or crop type. Multiplying this number by the field size, and average crop yield will give the Annual_Yield.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Weather_station_data (CSV)**\n",
    "\n",
    "- **Weather_station_ID:** The weather station the data originated from. (Int)\n",
    "\n",
    "- **Message:** The weather data was captured by sensors at the stations, in the format of text messages.(Str)\n",
    "\n",
    "**Weather_data_field_mapping (CSV)**\n",
    "\n",
    "- **Field_ID:** The id of the field that is connected to a weather station. This is the key we can use to join the weather station ID to the original data. (Int)\n",
    "\n",
    "- **Weather_station_ID:** The weather station that is connected to a field. If a field has `weather_station_ID = 0` then that field is closest to weather station 0. (Int)\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cca3f5",
   "metadata": {},
   "source": [
    "# Dealing with a friendly warning from Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70849ec4",
   "metadata": {},
   "source": [
    "If you are running this notebook in `Python 3.12` or later, you might get a warning if you run the imports below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33c121c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5564ea8",
   "metadata": {},
   "source": [
    "If you are lucky enough to see this warning, it let's us know that Pandas is changing soon and will require another package to be installed. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c05b1b",
   "metadata": {},
   "source": [
    "```python\n",
    "...2334042735.py:3: DeprecationWarning: \n",
    "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
    "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
    "but was not found to be installed on your system.\n",
    "If this would cause problems for you,\n",
    "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
    "        \n",
    "  import pandas as pd\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501ddc37",
   "metadata": {},
   "source": [
    "We can safely ignore these warnings, but soon our script will fail to import Pandas, so let's fix it today, and we won't have to worry about it for a long time. The warning tells us that Pyarrow will soon be a requirement to import Pandas, so we can just install it with pip. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab50c3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: Pyarrow in c:\\programdata\\anaconda3\\lib\\site-packages (11.0.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from Pyarrow) (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "%pip install Pyarrow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc7c0e7",
   "metadata": {},
   "source": [
    "# Cleaning up our data pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a858a84",
   "metadata": {},
   "source": [
    "When we pulled in the data last time, we actually made an assumption that our script worked. We assumed that all the fixes we made to the data actually made it in, and assumed that the database didn't change. But what if someone added more records, fixed the data on the database that we were making in our notebook, or added a new column of data? \n",
    "\n",
    "Last time we started to build what's known as a **data pipeline**. We often do this as data scientists. The data we work with is almost always stored in databases, and we don't want to transform, clean up or make changes to the database unless it is really beneficial. So we retrieve the data from the database, and in our workspace, we shape the data into a useful format for our goal. \n",
    "\n",
    "Last time we imported data with this code: (⚠️ Don't run it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fff3fd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # importing the Pandas package with an alias, pd\n",
    "from sqlalchemy import create_engine, text # Importing the SQL interface. If this fails, run !pip install sqlalchemy in another cell.\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Create an engine for the database\n",
    "engine = create_engine('sqlite:///Maji_Ndogo_farm_survey_small.db') #Make sure to have the .db file in the same directory as this notebook, and the file name matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f026e77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e62b8530",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = \"\"\"\n",
    "SELECT *\n",
    "FROM geographic_features\n",
    "LEFT JOIN weather_features USING (Field_ID)\n",
    "LEFT JOIN soil_and_crop_features USING (Field_ID)\n",
    "LEFT JOIN farm_management_features USING (Field_ID)\n",
    "\"\"\"\n",
    "\n",
    "# Create a connection object\n",
    "with engine.connect() as connection:\n",
    "    \n",
    "    # Use Pandas to execute the query and store the result in a DataFrame\n",
    "    MD_agric_df = pd.read_sql_query(text(sql_query), connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8e4173c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MD_agric_df.rename(columns={'Annual_yield': 'Crop_type_Temp', 'Crop_type': 'Annual_yield'}, inplace=True)\n",
    "MD_agric_df.rename(columns={'Crop_type_Temp': 'Crop_type'}, inplace=True)\n",
    "MD_agric_df['Elevation'] = MD_agric_df['Elevation'].abs()\n",
    "\n",
    "# Correcting 'Crop_type' column\n",
    "def correct_crop_type(crop):\n",
    "    crop = crop.strip()  # Remove trailing spaces\n",
    "    corrections = {\n",
    "        'cassaval': 'cassava',\n",
    "        'wheatn': 'wheat',\n",
    "        'teaa': 'tea'\n",
    "    }\n",
    "    return corrections.get(crop, crop)  # Get the corrected crop type, or return the original if not in corrections\n",
    "\n",
    "# Apply the correction function to the Crop_type column\n",
    "MD_agric_df['Crop_type'] = MD_agric_df['Crop_type'].apply(correct_crop_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7df10cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_station_df = pd.read_csv(\"https://raw.githubusercontent.com/Explore-AI/Public-Data/master/Maji_Ndogo/Weather_station_data.csv\")\n",
    "weather_station_mapping_df = pd.read_csv(\"https://raw.githubusercontent.com/Explore-AI/Public-Data/master/Maji_Ndogo/Weather_data_field_mapping.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97717c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re # Importing the regex pattern\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "patterns = {\n",
    "    'Rainfall': r'(\\d+(\\.\\d+)?)\\s?mm',\n",
    "     'Temperature': r'(\\d+(\\.\\d+)?)\\s?C',\n",
    "    'Pollution_level': r'=\\s*(-?\\d+(\\.\\d+)?)|Pollution at \\s*(-?\\d+(\\.\\d+)?)'\n",
    "    }\n",
    "\n",
    "def extract_measurement(message):\n",
    "    \"\"\"\n",
    "    Extracts a numeric measurement value from a given message string.\n",
    "\n",
    "    The function applies regular expressions to identify and extract\n",
    "    numeric values related to different types of measurements such as\n",
    "    Rainfall, Average Temperatures, and Pollution Levels from a text message.\n",
    "    It returns the key of the matching record, and first matching value as a floating-point number.\n",
    "    \n",
    "    Parameters:\n",
    "    message (str): A string message containing the measurement information.\n",
    "\n",
    "    Returns:\n",
    "    float: The extracted numeric value of the measurement if a match is found;\n",
    "           otherwise, None.\n",
    "\n",
    "    The function uses the following patterns for extraction:\n",
    "    - Rainfall: Matches numbers (including decimal) followed by 'mm', optionally spaced.\n",
    "    - Ave_temps: Matches numbers (including decimal) followed by 'C', optionally spaced.\n",
    "    - Pollution_level: Matches numbers (including decimal) following 'Pollution at' or '='.\n",
    "    \n",
    "    Example usage:\n",
    "    extract_measurement(\"【2022-01-04 21:47:48】温度感应: 现在温度是 12.82C.\")\n",
    "    # Returns: 'Temperature', 12.82\n",
    "    \"\"\"\n",
    "    \n",
    "    for key, pattern in patterns.items(): # Loop through all of the patterns and check if it matches the pattern value.\n",
    "        match = re.search(pattern, message)\n",
    "        if match:\n",
    "            # Extract the first group that matches, which should be the measurement value if all previous matches are empty.\n",
    "            # print(match.groups()) # Uncomment this line to help you debug your regex patterns.\n",
    "            return key, float(next((x for x in match.groups() if x is not None)))\n",
    "    \n",
    "    return None, None\n",
    "\n",
    "# The function creates a tuple with the measurement type and value into a Pandas Series\n",
    "result = weather_station_df['Message'].apply(extract_measurement)\n",
    "\n",
    "# Create separate columns for 'Measurement' and 'extracted_value' by unpacking the tuple with Lambda functions.\n",
    "weather_station_df['Measurement'] = result.apply(lambda x: x[0])\n",
    "weather_station_df['Value'] = result.apply(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36d829c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Measurement</th>\n",
       "      <th>Pollution_level</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Temperature</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weather_station_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.352791</td>\n",
       "      <td>1575.953750</td>\n",
       "      <td>13.403900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.257333</td>\n",
       "      <td>577.383910</td>\n",
       "      <td>12.998899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.043858</td>\n",
       "      <td>1690.955324</td>\n",
       "      <td>13.179717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.238190</td>\n",
       "      <td>905.191397</td>\n",
       "      <td>13.256779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.128261</td>\n",
       "      <td>1200.183505</td>\n",
       "      <td>13.188571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Measurement         Pollution_level     Rainfall  Temperature\n",
       "Weather_station_ID                                           \n",
       "0                          0.352791  1575.953750    13.403900\n",
       "1                          0.257333   577.383910    12.998899\n",
       "2                          0.043858  1690.955324    13.179717\n",
       "3                          0.238190   905.191397    13.256779\n",
       "4                          0.128261  1200.183505    13.188571"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The function creates a tuple with the measurement type and value into a Pandas Series\n",
    "result = weather_station_df['Message'].apply(extract_measurement)\n",
    "\n",
    "# Create separate columns for 'Measurement' and 'extracted_value' by unpacking the tuple with Lambda functions.\n",
    "weather_station_df['Measurement'] = result.apply(lambda x: x[0])\n",
    "weather_station_df['Value'] = result.apply(lambda x: x[1])\n",
    "\n",
    "weather_station_means = weather_station_df.groupby(by = ['Weather_station_ID','Measurement'])['Value'].mean(numeric_only = True)\n",
    "weather_station_means = weather_station_means.unstack()\n",
    "weather_station_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13e22228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weather_station_ID</th>\n",
       "      <th>Message</th>\n",
       "      <th>Measurement</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Weather_station_ID, Message, Measurement, Value]\n",
       "Index: []"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use this line of code to see which messages are not assigned yet.\n",
    "weather_station_df[(weather_station_df['Measurement'] == None)|(weather_station_df['Value'].isna())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9afa1e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pollution_level</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Temperature</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weather_station</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.367706</td>\n",
       "      <td>1522.894473</td>\n",
       "      <td>13.393418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.244627</td>\n",
       "      <td>568.445319</td>\n",
       "      <td>13.058085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.043810</td>\n",
       "      <td>1705.834280</td>\n",
       "      <td>13.168364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.271464</td>\n",
       "      <td>931.607860</td>\n",
       "      <td>13.224666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.139913</td>\n",
       "      <td>1168.991800</td>\n",
       "      <td>13.197995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Pollution_level     Rainfall  Temperature\n",
       "Weather_station                                           \n",
       "0                       0.367706  1522.894473    13.393418\n",
       "1                       0.244627   568.445319    13.058085\n",
       "2                       0.043810  1705.834280    13.168364\n",
       "3                       0.271464   931.607860    13.224666\n",
       "4                       0.139913  1168.991800    13.197995"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "MD_agric_df = MD_agric_df.merge(weather_station_mapping_df,on = 'Field_ID', how='left')\n",
    "MD_agric_df.drop(columns=\"Unnamed: 0\")\n",
    "MD_agric_df_weather_means = MD_agric_df.groupby(\"Weather_station\").mean(numeric_only = True)[['Pollution_level','Rainfall', 'Ave_temps']]\n",
    "\n",
    "MD_agric_df_weather_means = MD_agric_df_weather_means.rename(columns = {'Ave_temps':\"Temperature\"})\n",
    "MD_agric_df_weather_means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b59f3d6",
   "metadata": {},
   "source": [
    "We have to copy that code across from another notebook, and we may miss some blocks or lines of code. We may not copy over the code in the right order, and we may not have documented the code well either. \n",
    "\n",
    "Do you also think this is a massive block of code that feels like it is in the way of our analysis? Is it simple to follow and simple to change? \n",
    "\n",
    "No! So let's spend a bit of time building a proper data pipeline that imports the data from the different sources we have, cleans up the data, and tests whether our data is what we expect it to be. We want to do all of this in a way that doesn't cause our notebook to be filled with thousands of lines of code and become a nightmare to debug. As a final step, we want to automate a few simple data validation checks in our code.\n",
    "\n",
    "To do this we're going to re-organise or **refactor** our code into modules. We're going to reorganise all of the code into smaller modules so our code is more readable, maintainable and extendable. \n",
    "\n",
    "We can create a module to interact with the database, a module to transform and clean the field-related data and another module to process the weather data.\n",
    "\n",
    "<br>\n",
    "\n",
    "So here's the plan: \n",
    "\n",
    "1. Gather all of the code from our last \"pipeline\".\n",
    "\n",
    "2. Re-organise the code into our new three modules: \n",
    "\n",
    "    a. `data_ingesation.py` - All SQL-related functions, and web-based data retrieval.\n",
    "\n",
    "    b. `field_data_processor.py` - All transformations, cleanup, and merging functionality.\n",
    "\n",
    "    c. `weather_data_processor.py` - All transformations and cleanup of the weather station data.\n",
    "\n",
    "3. Copy our code into the modules and test their functionality.\n",
    "\n",
    "4. Create automated data validation tests to ensure our data is as we expect it to be.\n",
    "\n",
    "Once we're done with that, we're going to jump into the reason why we're here. So let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6a0d5b",
   "metadata": {},
   "source": [
    "# Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8a491c",
   "metadata": {},
   "source": [
    "Why are we doing this? Well, we want to reduce our data pipeline code to a couple of lines like this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66c68f47",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'field_processor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m field_processor\u001b[38;5;241m.\u001b[39mprocess()\n\u001b[0;32m      2\u001b[0m field_df \u001b[38;5;241m=\u001b[39m field_processor\u001b[38;5;241m.\u001b[39mdf\n\u001b[0;32m      4\u001b[0m weather_processor\u001b[38;5;241m.\u001b[39mprocess()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'field_processor' is not defined"
     ]
    }
   ],
   "source": [
    "field_processor.process()\n",
    "field_df = field_processor.df\n",
    "\n",
    "weather_processor.process()\n",
    "field_df = field_processor.weather_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b766dd0",
   "metadata": {},
   "source": [
    "We're going to need a bit more code, but we want to press a button and go from databases and CSVs to a Pandas DataFrame. All of the code and processes are happening in the modules and we get the end result. The second big motivator is to make our code more modular. If we want to debug a problem in the field data, we know where to go, and if we want to import other IoT weather sensors we can just modify the weather data module.\n",
    "\n",
    "The first challenge; automating the data ingestion. There are two places we're fetching data:\n",
    "1. SQLite database - We need to create an SQLite engine, connect to the database, run a query and return a pandas DataFrame.\n",
    "2. Web CSV file - Read the CSV data from the web, and import it as a DataFrame.\n",
    "\n",
    "So let's start building!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e22624",
   "metadata": {},
   "source": [
    "## Data ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0bffbb",
   "metadata": {},
   "source": [
    "Ok, so first up, let's grab the code that interacted with the database, and the web CSV files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c9a92a",
   "metadata": {},
   "source": [
    "SQL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0f0f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # importing the Pandas package with an alias, pd\n",
    "from sqlalchemy import create_engine, text # Importing the SQL interface. If this fails, run !pip install sqlalchemy in another cell.\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Create an engine for the database\n",
    "engine = create_engine('sqlite:///Maji_Ndogo_farm_survey_small.db') #Make sure to have the .db file in the same directory as this notebook, and the file name matches.\n",
    "\n",
    "\n",
    "sql_query = \"\"\"\n",
    "SELECT *\n",
    "FROM geographic_features\n",
    "LEFT JOIN weather_features USING (Field_ID)\n",
    "LEFT JOIN soil_and_crop_features USING (Field_ID)\n",
    "LEFT JOIN farm_management_features USING (Field_ID)\n",
    "\"\"\"\n",
    "\n",
    "# Create a connection object\n",
    "with engine.connect() as connection:\n",
    "    \n",
    "    # Use Pandas to execute the query and store the result in a DataFrame\n",
    "    MD_agric_df = pd.read_sql_query(text(sql_query), connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6700c2c",
   "metadata": {},
   "source": [
    "CSV files: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809e9d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_station_df = pd.read_csv(\"https://raw.githubusercontent.com/Explore-AI/Public-Data/master/Maji_Ndogo/Weather_station_data.csv\")\n",
    "weather_station_mapping_df = pd.read_csv(\"https://raw.githubusercontent.com/Explore-AI/Public-Data/master/Maji_Ndogo/Weather_data_field_mapping.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21df87d7",
   "metadata": {},
   "source": [
    "Creating modules in Jupyter notebooks is a bit of a pain. If we make changes to the `module.py` file, we have to restart the notebook kernel and import the module again in order to apply those changes. So, we're going to fully develop it, test it in this notebook, and only then, move it to a `data_ingestion.py` file, and import it. \n",
    "\n",
    "To create a module, our code should ideally be encapsulated in functions or classes. How do we choose?\n",
    "\n",
    "Since the process of connecting to a database, and querying some data is relatively straightforward, functions seemed like the best fit. Functions allow us to encapsulate the necessary steps in clear, reusable blocks of code without the overhead of managing class objects. It's like using a **simple tool** for a specific task — pick it up, use it, and put it back without needing to remember anything about the last use.\n",
    "\n",
    "On the other hand, our **data processing** modules are a bit more complex. These modules not only perform various operations on the data but also need to keep track of the data as it goes through these processes. For this, we use **classes** to **create DataFrame objects** as attributes. This approach simplifies data handling since we're passing the object around, which inherently knows its data and the operations it can perform within the class.\n",
    "\n",
    "This idea ties back to OOP. Class objects are designed to deal with data and operations on that data via methods, while functions are made to do the simpler tasks.\n",
    "\n",
    "So for **data ingestion**, we're just going to use functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7947076",
   "metadata": {},
   "source": [
    "So our **main task** will be to **convert the data ingestion code into functions** that we can call from the module."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85e6de7",
   "metadata": {},
   "source": [
    "So this code: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940d7b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an engine for the database\n",
    "engine = create_engine('sqlite:///Maji_Ndogo_farm_survey_small.db') #Make sure to have the .db file in the same directory as this notebook, and the file name matches.\n",
    "\n",
    "\n",
    "sql_query = \"\"\"\n",
    "SELECT *\n",
    "FROM geographic_features\n",
    "LEFT JOIN weather_features USING (Field_ID)\n",
    "LEFT JOIN soil_and_crop_features USING (Field_ID)\n",
    "LEFT JOIN farm_management_features USING (Field_ID)\n",
    "\"\"\"\n",
    "\n",
    "# Create a connection object\n",
    "with engine.connect() as connection:\n",
    "    \n",
    "    # Use Pandas to execute the query and store the result in a DataFrame\n",
    "    MD_agric_df = pd.read_sql_query(text(sql_query), connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9248b4e",
   "metadata": {},
   "source": [
    "Becomes neat, modular functions: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ea12a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_db_engine(db_path):\n",
    "    engine = create_engine(db_path)\n",
    "    return engine\n",
    "\n",
    "def query_data(engine, sql_query):\n",
    "    with engine.connect() as connection:\n",
    "        df = pd.read_sql_query(text(sql_query), connection)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8258e138",
   "metadata": {},
   "source": [
    "So if we call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a0d4832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Engine(sqlite:///Maji_Ndogo_farm_survey_small.db)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_db_engine('sqlite:///Maji_Ndogo_farm_survey_small.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bff0102",
   "metadata": {},
   "source": [
    "We get the SQL engine object which we can use with the query to connect to the database, and run a query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55b0125d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Field_ID</th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Location</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Min_temperature_C</th>\n",
       "      <th>Max_temperature_C</th>\n",
       "      <th>Ave_temps</th>\n",
       "      <th>Soil_fertility</th>\n",
       "      <th>Soil_type</th>\n",
       "      <th>pH</th>\n",
       "      <th>Pollution_level</th>\n",
       "      <th>Plot_size</th>\n",
       "      <th>Crop_type</th>\n",
       "      <th>Annual_yield</th>\n",
       "      <th>Standard_yield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40734</td>\n",
       "      <td>786.05580</td>\n",
       "      <td>-7.389911</td>\n",
       "      <td>-7.556202</td>\n",
       "      <td>Rural_Akatsi</td>\n",
       "      <td>14.795113</td>\n",
       "      <td>1125.2</td>\n",
       "      <td>-3.1</td>\n",
       "      <td>33.1</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>Sandy</td>\n",
       "      <td>6.169393</td>\n",
       "      <td>8.526684e-02</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.751354</td>\n",
       "      <td>cassava</td>\n",
       "      <td>0.577964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30629</td>\n",
       "      <td>674.33410</td>\n",
       "      <td>-7.736849</td>\n",
       "      <td>-1.051539</td>\n",
       "      <td>Rural_Sokoto</td>\n",
       "      <td>11.374611</td>\n",
       "      <td>1450.7</td>\n",
       "      <td>-3.9</td>\n",
       "      <td>30.6</td>\n",
       "      <td>13.35</td>\n",
       "      <td>0.64</td>\n",
       "      <td>Volcanic</td>\n",
       "      <td>5.676648</td>\n",
       "      <td>3.996838e-01</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.069865</td>\n",
       "      <td>cassava</td>\n",
       "      <td>0.486302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39924</td>\n",
       "      <td>826.53390</td>\n",
       "      <td>-9.926616</td>\n",
       "      <td>0.115156</td>\n",
       "      <td>Rural_Sokoto</td>\n",
       "      <td>11.339692</td>\n",
       "      <td>2208.9</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>28.4</td>\n",
       "      <td>13.30</td>\n",
       "      <td>0.69</td>\n",
       "      <td>Volcanic</td>\n",
       "      <td>5.331993</td>\n",
       "      <td>3.580286e-01</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.208801</td>\n",
       "      <td>tea</td>\n",
       "      <td>0.649647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5754</td>\n",
       "      <td>574.94617</td>\n",
       "      <td>-2.420131</td>\n",
       "      <td>-6.592215</td>\n",
       "      <td>Rural_Kilimani</td>\n",
       "      <td>7.109855</td>\n",
       "      <td>328.8</td>\n",
       "      <td>-5.8</td>\n",
       "      <td>32.2</td>\n",
       "      <td>13.20</td>\n",
       "      <td>0.54</td>\n",
       "      <td>Loamy</td>\n",
       "      <td>5.328150</td>\n",
       "      <td>2.866871e-01</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.277635</td>\n",
       "      <td>cassava</td>\n",
       "      <td>0.532348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14146</td>\n",
       "      <td>886.35300</td>\n",
       "      <td>-3.055434</td>\n",
       "      <td>-7.952609</td>\n",
       "      <td>Rural_Kilimani</td>\n",
       "      <td>55.007656</td>\n",
       "      <td>785.2</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>31.0</td>\n",
       "      <td>14.25</td>\n",
       "      <td>0.72</td>\n",
       "      <td>Sandy</td>\n",
       "      <td>5.721234</td>\n",
       "      <td>4.319027e-02</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.832614</td>\n",
       "      <td>wheat</td>\n",
       "      <td>0.555076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5649</th>\n",
       "      <td>11472</td>\n",
       "      <td>681.36145</td>\n",
       "      <td>-7.358371</td>\n",
       "      <td>-6.254369</td>\n",
       "      <td>Rural_Akatsi</td>\n",
       "      <td>16.213196</td>\n",
       "      <td>885.7</td>\n",
       "      <td>-4.3</td>\n",
       "      <td>33.4</td>\n",
       "      <td>14.55</td>\n",
       "      <td>0.61</td>\n",
       "      <td>Sandy</td>\n",
       "      <td>5.741063</td>\n",
       "      <td>3.286828e-01</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.609930</td>\n",
       "      <td>potato</td>\n",
       "      <td>0.554482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5650</th>\n",
       "      <td>19660</td>\n",
       "      <td>667.02120</td>\n",
       "      <td>-3.154559</td>\n",
       "      <td>-4.475046</td>\n",
       "      <td>Rural_Kilimani</td>\n",
       "      <td>2.397553</td>\n",
       "      <td>501.1</td>\n",
       "      <td>-4.8</td>\n",
       "      <td>32.1</td>\n",
       "      <td>13.65</td>\n",
       "      <td>0.54</td>\n",
       "      <td>Sandy</td>\n",
       "      <td>5.445833</td>\n",
       "      <td>1.602583e-01</td>\n",
       "      <td>8.7</td>\n",
       "      <td>3.812289</td>\n",
       "      <td>maize</td>\n",
       "      <td>0.438194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5651</th>\n",
       "      <td>41296</td>\n",
       "      <td>670.77900</td>\n",
       "      <td>-14.472861</td>\n",
       "      <td>-6.110221</td>\n",
       "      <td>Rural_Hawassa</td>\n",
       "      <td>7.636470</td>\n",
       "      <td>1586.6</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>33.4</td>\n",
       "      <td>14.80</td>\n",
       "      <td>0.64</td>\n",
       "      <td>Volcanic</td>\n",
       "      <td>5.385873</td>\n",
       "      <td>8.221326e-09</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.681629</td>\n",
       "      <td>tea</td>\n",
       "      <td>0.800776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5652</th>\n",
       "      <td>33090</td>\n",
       "      <td>429.48840</td>\n",
       "      <td>-14.653089</td>\n",
       "      <td>-6.984116</td>\n",
       "      <td>Rural_Hawassa</td>\n",
       "      <td>13.944720</td>\n",
       "      <td>1272.2</td>\n",
       "      <td>-6.2</td>\n",
       "      <td>34.6</td>\n",
       "      <td>14.20</td>\n",
       "      <td>0.63</td>\n",
       "      <td>Silt</td>\n",
       "      <td>5.562508</td>\n",
       "      <td>6.917245e-10</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.659874</td>\n",
       "      <td>cassava</td>\n",
       "      <td>0.507595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5653</th>\n",
       "      <td>8375</td>\n",
       "      <td>763.09030</td>\n",
       "      <td>-4.317028</td>\n",
       "      <td>-6.344461</td>\n",
       "      <td>Rural_Kilimani</td>\n",
       "      <td>35.189430</td>\n",
       "      <td>516.4</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>29.6</td>\n",
       "      <td>12.90</td>\n",
       "      <td>0.64</td>\n",
       "      <td>Sandy</td>\n",
       "      <td>5.087792</td>\n",
       "      <td>2.612715e-01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.226532</td>\n",
       "      <td>wheat</td>\n",
       "      <td>0.453064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5654 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Field_ID  Elevation   Latitude  Longitude        Location      Slope  \\\n",
       "0        40734  786.05580  -7.389911  -7.556202    Rural_Akatsi  14.795113   \n",
       "1        30629  674.33410  -7.736849  -1.051539    Rural_Sokoto  11.374611   \n",
       "2        39924  826.53390  -9.926616   0.115156    Rural_Sokoto  11.339692   \n",
       "3         5754  574.94617  -2.420131  -6.592215  Rural_Kilimani   7.109855   \n",
       "4        14146  886.35300  -3.055434  -7.952609  Rural_Kilimani  55.007656   \n",
       "...        ...        ...        ...        ...             ...        ...   \n",
       "5649     11472  681.36145  -7.358371  -6.254369    Rural_Akatsi  16.213196   \n",
       "5650     19660  667.02120  -3.154559  -4.475046  Rural_Kilimani   2.397553   \n",
       "5651     41296  670.77900 -14.472861  -6.110221   Rural_Hawassa   7.636470   \n",
       "5652     33090  429.48840 -14.653089  -6.984116   Rural_Hawassa  13.944720   \n",
       "5653      8375  763.09030  -4.317028  -6.344461  Rural_Kilimani  35.189430   \n",
       "\n",
       "      Rainfall  Min_temperature_C  Max_temperature_C  Ave_temps  \\\n",
       "0       1125.2               -3.1               33.1      15.00   \n",
       "1       1450.7               -3.9               30.6      13.35   \n",
       "2       2208.9               -1.8               28.4      13.30   \n",
       "3        328.8               -5.8               32.2      13.20   \n",
       "4        785.2               -2.5               31.0      14.25   \n",
       "...        ...                ...                ...        ...   \n",
       "5649     885.7               -4.3               33.4      14.55   \n",
       "5650     501.1               -4.8               32.1      13.65   \n",
       "5651    1586.6               -3.8               33.4      14.80   \n",
       "5652    1272.2               -6.2               34.6      14.20   \n",
       "5653     516.4               -3.8               29.6      12.90   \n",
       "\n",
       "      Soil_fertility Soil_type        pH  Pollution_level  Plot_size  \\\n",
       "0               0.62     Sandy  6.169393     8.526684e-02        1.3   \n",
       "1               0.64  Volcanic  5.676648     3.996838e-01        2.2   \n",
       "2               0.69  Volcanic  5.331993     3.580286e-01        3.4   \n",
       "3               0.54     Loamy  5.328150     2.866871e-01        2.4   \n",
       "4               0.72     Sandy  5.721234     4.319027e-02        1.5   \n",
       "...              ...       ...       ...              ...        ...   \n",
       "5649            0.61     Sandy  5.741063     3.286828e-01        1.1   \n",
       "5650            0.54     Sandy  5.445833     1.602583e-01        8.7   \n",
       "5651            0.64  Volcanic  5.385873     8.221326e-09        2.1   \n",
       "5652            0.63      Silt  5.562508     6.917245e-10        1.3   \n",
       "5653            0.64     Sandy  5.087792     2.612715e-01        0.5   \n",
       "\n",
       "      Crop_type Annual_yield  Standard_yield  \n",
       "0      0.751354      cassava        0.577964  \n",
       "1      1.069865      cassava        0.486302  \n",
       "2      2.208801          tea        0.649647  \n",
       "3      1.277635      cassava        0.532348  \n",
       "4      0.832614        wheat        0.555076  \n",
       "...         ...          ...             ...  \n",
       "5649   0.609930       potato        0.554482  \n",
       "5650   3.812289        maize        0.438194  \n",
       "5651   1.681629          tea        0.800776  \n",
       "5652   0.659874      cassava        0.507595  \n",
       "5653   0.226532        wheat        0.453064  \n",
       "\n",
       "[5654 rows x 18 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SQL_engine = create_db_engine('sqlite:///Maji_Ndogo_farm_survey_small.db')\n",
    "\n",
    "sql_query = \"\"\"\n",
    "SELECT *\n",
    "FROM geographic_features\n",
    "LEFT JOIN weather_features USING (Field_ID)\n",
    "LEFT JOIN soil_and_crop_features USING (Field_ID)\n",
    "LEFT JOIN farm_management_features USING (Field_ID)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "df = query_data(SQL_engine, sql_query)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef469416",
   "metadata": {},
   "source": [
    "We can even call the `create_db_engine()` function inside the `query_data()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66b65d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Field_ID</th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Location</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Min_temperature_C</th>\n",
       "      <th>Max_temperature_C</th>\n",
       "      <th>Ave_temps</th>\n",
       "      <th>Soil_fertility</th>\n",
       "      <th>Soil_type</th>\n",
       "      <th>pH</th>\n",
       "      <th>Pollution_level</th>\n",
       "      <th>Plot_size</th>\n",
       "      <th>Crop_type</th>\n",
       "      <th>Annual_yield</th>\n",
       "      <th>Standard_yield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40734</td>\n",
       "      <td>786.05580</td>\n",
       "      <td>-7.389911</td>\n",
       "      <td>-7.556202</td>\n",
       "      <td>Rural_Akatsi</td>\n",
       "      <td>14.795113</td>\n",
       "      <td>1125.2</td>\n",
       "      <td>-3.1</td>\n",
       "      <td>33.1</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>Sandy</td>\n",
       "      <td>6.169393</td>\n",
       "      <td>8.526684e-02</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.751354</td>\n",
       "      <td>cassava</td>\n",
       "      <td>0.577964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30629</td>\n",
       "      <td>674.33410</td>\n",
       "      <td>-7.736849</td>\n",
       "      <td>-1.051539</td>\n",
       "      <td>Rural_Sokoto</td>\n",
       "      <td>11.374611</td>\n",
       "      <td>1450.7</td>\n",
       "      <td>-3.9</td>\n",
       "      <td>30.6</td>\n",
       "      <td>13.35</td>\n",
       "      <td>0.64</td>\n",
       "      <td>Volcanic</td>\n",
       "      <td>5.676648</td>\n",
       "      <td>3.996838e-01</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.069865</td>\n",
       "      <td>cassava</td>\n",
       "      <td>0.486302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39924</td>\n",
       "      <td>826.53390</td>\n",
       "      <td>-9.926616</td>\n",
       "      <td>0.115156</td>\n",
       "      <td>Rural_Sokoto</td>\n",
       "      <td>11.339692</td>\n",
       "      <td>2208.9</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>28.4</td>\n",
       "      <td>13.30</td>\n",
       "      <td>0.69</td>\n",
       "      <td>Volcanic</td>\n",
       "      <td>5.331993</td>\n",
       "      <td>3.580286e-01</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.208801</td>\n",
       "      <td>tea</td>\n",
       "      <td>0.649647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5754</td>\n",
       "      <td>574.94617</td>\n",
       "      <td>-2.420131</td>\n",
       "      <td>-6.592215</td>\n",
       "      <td>Rural_Kilimani</td>\n",
       "      <td>7.109855</td>\n",
       "      <td>328.8</td>\n",
       "      <td>-5.8</td>\n",
       "      <td>32.2</td>\n",
       "      <td>13.20</td>\n",
       "      <td>0.54</td>\n",
       "      <td>Loamy</td>\n",
       "      <td>5.328150</td>\n",
       "      <td>2.866871e-01</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.277635</td>\n",
       "      <td>cassava</td>\n",
       "      <td>0.532348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14146</td>\n",
       "      <td>886.35300</td>\n",
       "      <td>-3.055434</td>\n",
       "      <td>-7.952609</td>\n",
       "      <td>Rural_Kilimani</td>\n",
       "      <td>55.007656</td>\n",
       "      <td>785.2</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>31.0</td>\n",
       "      <td>14.25</td>\n",
       "      <td>0.72</td>\n",
       "      <td>Sandy</td>\n",
       "      <td>5.721234</td>\n",
       "      <td>4.319027e-02</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.832614</td>\n",
       "      <td>wheat</td>\n",
       "      <td>0.555076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5649</th>\n",
       "      <td>11472</td>\n",
       "      <td>681.36145</td>\n",
       "      <td>-7.358371</td>\n",
       "      <td>-6.254369</td>\n",
       "      <td>Rural_Akatsi</td>\n",
       "      <td>16.213196</td>\n",
       "      <td>885.7</td>\n",
       "      <td>-4.3</td>\n",
       "      <td>33.4</td>\n",
       "      <td>14.55</td>\n",
       "      <td>0.61</td>\n",
       "      <td>Sandy</td>\n",
       "      <td>5.741063</td>\n",
       "      <td>3.286828e-01</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.609930</td>\n",
       "      <td>potato</td>\n",
       "      <td>0.554482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5650</th>\n",
       "      <td>19660</td>\n",
       "      <td>667.02120</td>\n",
       "      <td>-3.154559</td>\n",
       "      <td>-4.475046</td>\n",
       "      <td>Rural_Kilimani</td>\n",
       "      <td>2.397553</td>\n",
       "      <td>501.1</td>\n",
       "      <td>-4.8</td>\n",
       "      <td>32.1</td>\n",
       "      <td>13.65</td>\n",
       "      <td>0.54</td>\n",
       "      <td>Sandy</td>\n",
       "      <td>5.445833</td>\n",
       "      <td>1.602583e-01</td>\n",
       "      <td>8.7</td>\n",
       "      <td>3.812289</td>\n",
       "      <td>maize</td>\n",
       "      <td>0.438194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5651</th>\n",
       "      <td>41296</td>\n",
       "      <td>670.77900</td>\n",
       "      <td>-14.472861</td>\n",
       "      <td>-6.110221</td>\n",
       "      <td>Rural_Hawassa</td>\n",
       "      <td>7.636470</td>\n",
       "      <td>1586.6</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>33.4</td>\n",
       "      <td>14.80</td>\n",
       "      <td>0.64</td>\n",
       "      <td>Volcanic</td>\n",
       "      <td>5.385873</td>\n",
       "      <td>8.221326e-09</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.681629</td>\n",
       "      <td>tea</td>\n",
       "      <td>0.800776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5652</th>\n",
       "      <td>33090</td>\n",
       "      <td>429.48840</td>\n",
       "      <td>-14.653089</td>\n",
       "      <td>-6.984116</td>\n",
       "      <td>Rural_Hawassa</td>\n",
       "      <td>13.944720</td>\n",
       "      <td>1272.2</td>\n",
       "      <td>-6.2</td>\n",
       "      <td>34.6</td>\n",
       "      <td>14.20</td>\n",
       "      <td>0.63</td>\n",
       "      <td>Silt</td>\n",
       "      <td>5.562508</td>\n",
       "      <td>6.917245e-10</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.659874</td>\n",
       "      <td>cassava</td>\n",
       "      <td>0.507595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5653</th>\n",
       "      <td>8375</td>\n",
       "      <td>763.09030</td>\n",
       "      <td>-4.317028</td>\n",
       "      <td>-6.344461</td>\n",
       "      <td>Rural_Kilimani</td>\n",
       "      <td>35.189430</td>\n",
       "      <td>516.4</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>29.6</td>\n",
       "      <td>12.90</td>\n",
       "      <td>0.64</td>\n",
       "      <td>Sandy</td>\n",
       "      <td>5.087792</td>\n",
       "      <td>2.612715e-01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.226532</td>\n",
       "      <td>wheat</td>\n",
       "      <td>0.453064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5654 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Field_ID  Elevation   Latitude  Longitude        Location      Slope  \\\n",
       "0        40734  786.05580  -7.389911  -7.556202    Rural_Akatsi  14.795113   \n",
       "1        30629  674.33410  -7.736849  -1.051539    Rural_Sokoto  11.374611   \n",
       "2        39924  826.53390  -9.926616   0.115156    Rural_Sokoto  11.339692   \n",
       "3         5754  574.94617  -2.420131  -6.592215  Rural_Kilimani   7.109855   \n",
       "4        14146  886.35300  -3.055434  -7.952609  Rural_Kilimani  55.007656   \n",
       "...        ...        ...        ...        ...             ...        ...   \n",
       "5649     11472  681.36145  -7.358371  -6.254369    Rural_Akatsi  16.213196   \n",
       "5650     19660  667.02120  -3.154559  -4.475046  Rural_Kilimani   2.397553   \n",
       "5651     41296  670.77900 -14.472861  -6.110221   Rural_Hawassa   7.636470   \n",
       "5652     33090  429.48840 -14.653089  -6.984116   Rural_Hawassa  13.944720   \n",
       "5653      8375  763.09030  -4.317028  -6.344461  Rural_Kilimani  35.189430   \n",
       "\n",
       "      Rainfall  Min_temperature_C  Max_temperature_C  Ave_temps  \\\n",
       "0       1125.2               -3.1               33.1      15.00   \n",
       "1       1450.7               -3.9               30.6      13.35   \n",
       "2       2208.9               -1.8               28.4      13.30   \n",
       "3        328.8               -5.8               32.2      13.20   \n",
       "4        785.2               -2.5               31.0      14.25   \n",
       "...        ...                ...                ...        ...   \n",
       "5649     885.7               -4.3               33.4      14.55   \n",
       "5650     501.1               -4.8               32.1      13.65   \n",
       "5651    1586.6               -3.8               33.4      14.80   \n",
       "5652    1272.2               -6.2               34.6      14.20   \n",
       "5653     516.4               -3.8               29.6      12.90   \n",
       "\n",
       "      Soil_fertility Soil_type        pH  Pollution_level  Plot_size  \\\n",
       "0               0.62     Sandy  6.169393     8.526684e-02        1.3   \n",
       "1               0.64  Volcanic  5.676648     3.996838e-01        2.2   \n",
       "2               0.69  Volcanic  5.331993     3.580286e-01        3.4   \n",
       "3               0.54     Loamy  5.328150     2.866871e-01        2.4   \n",
       "4               0.72     Sandy  5.721234     4.319027e-02        1.5   \n",
       "...              ...       ...       ...              ...        ...   \n",
       "5649            0.61     Sandy  5.741063     3.286828e-01        1.1   \n",
       "5650            0.54     Sandy  5.445833     1.602583e-01        8.7   \n",
       "5651            0.64  Volcanic  5.385873     8.221326e-09        2.1   \n",
       "5652            0.63      Silt  5.562508     6.917245e-10        1.3   \n",
       "5653            0.64     Sandy  5.087792     2.612715e-01        0.5   \n",
       "\n",
       "      Crop_type Annual_yield  Standard_yield  \n",
       "0      0.751354      cassava        0.577964  \n",
       "1      1.069865      cassava        0.486302  \n",
       "2      2.208801          tea        0.649647  \n",
       "3      1.277635      cassava        0.532348  \n",
       "4      0.832614        wheat        0.555076  \n",
       "...         ...          ...             ...  \n",
       "5649   0.609930       potato        0.554482  \n",
       "5650   3.812289        maize        0.438194  \n",
       "5651   1.681629          tea        0.800776  \n",
       "5652   0.659874      cassava        0.507595  \n",
       "5653   0.226532        wheat        0.453064  \n",
       "\n",
       "[5654 rows x 18 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_query = \"\"\"\n",
    "SELECT *\n",
    "FROM geographic_features\n",
    "LEFT JOIN weather_features USING (Field_ID)\n",
    "LEFT JOIN soil_and_crop_features USING (Field_ID)\n",
    "LEFT JOIN farm_management_features USING (Field_ID)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "df = query_data(create_db_engine('sqlite:///Maji_Ndogo_farm_survey_small.db'), sql_query)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca659546",
   "metadata": {},
   "source": [
    "This seems simple, but let's think for a second about what could go wrong. For example, what if there is a problem like the database has a schema, and no actual data? Or our query doesn't return any data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "892fbeaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Field_ID</th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Location</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Min_temperature_C</th>\n",
       "      <th>Max_temperature_C</th>\n",
       "      <th>Ave_temps</th>\n",
       "      <th>Soil_fertility</th>\n",
       "      <th>Soil_type</th>\n",
       "      <th>pH</th>\n",
       "      <th>Pollution_level</th>\n",
       "      <th>Plot_size</th>\n",
       "      <th>Crop_type</th>\n",
       "      <th>Annual_yield</th>\n",
       "      <th>Standard_yield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Field_ID, Elevation, Latitude, Longitude, Location, Slope, Rainfall, Min_temperature_C, Max_temperature_C, Ave_temps, Soil_fertility, Soil_type, pH, Pollution_level, Plot_size, Crop_type, Annual_yield, Standard_yield]\n",
       "Index: []"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SQL_engine = create_db_engine('sqlite:///Maji_Ndogo_farm_survey_small.db')\n",
    "\n",
    "sql_query = \"\"\"\n",
    "SELECT *\n",
    "FROM geographic_features\n",
    "LEFT JOIN weather_features USING (Field_ID)\n",
    "LEFT JOIN soil_and_crop_features USING (Field_ID)\n",
    "LEFT JOIN farm_management_features USING (Field_ID)\n",
    "WHERE Rainfall < 0 \n",
    "\"\"\"\n",
    "# The last line won't ever be true, so no results will be returned. \n",
    "\n",
    "df = query_data(SQL_engine, sql_query)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89985eb4",
   "metadata": {},
   "source": [
    "We get an empty DataFrame, because SQL returned an empty query result. When we try to filter results, we get an answer that would not make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ea68a976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: Rainfall, dtype: bool)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Rainfall'] > 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabaefaf",
   "metadata": {},
   "source": [
    "So to avoid this we need to add error handling into our code so that we stop the process if something is wrong, and tell us what the problem is before we continue. \n",
    "\n",
    "Secondly, to help us understand how our code is executing we're going to add some logs. While print statements can help us to debug our code, we have to remove them once our code goes into use, one by one. `logging` is a better way to debug our code than print statements because we can add `logging.INFO()` logs to know what our code is doing, and `logging.DEBUG()` statements that have more detail in case we want to debug a specific loop in a bit more in detail. There are also various other tools to use, and we can also silence all logging with a single line of code. If we used print statements, we will have to comment them out one by one. \n",
    "\n",
    "If we apply these two ideas, we get the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "12778c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "\n",
    "# Name our logger so we know that logs from this module come from the data_ingestion module\n",
    "logger = logging.getLogger('data_ingestion')\n",
    "\n",
    "# Set a basic logging message up that prints out a timestamp, the name of our logger, and the message\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "\n",
    "def create_db_engine(db_path):\n",
    "    try:\n",
    "        engine = create_engine(db_path)\n",
    "        # Test connection\n",
    "        with engine.connect() as conn:\n",
    "            pass\n",
    "        # test if the database engine was created successfully\n",
    "        logger.info(\"Database engine created successfully.\")\n",
    "        return engine # Return the engine object if it all works well\n",
    "    except ImportError: #If we get an ImportError, inform the user SQLAlchemy is not installed\n",
    "        logger.error(\"SQLAlchemy is required to use this function. Please install it first.\")\n",
    "        raise e\n",
    "    except Exception as e:# If we fail to create an engine inform the user\n",
    "        logger.error(f\"Failed to create database engine. Error: {e}\")\n",
    "        raise e\n",
    "    \n",
    "def query_data(engine, sql_query):\n",
    "    try:\n",
    "        with engine.connect() as connection:\n",
    "            df = pd.read_sql_query(text(sql_query), connection)\n",
    "        if df.empty:\n",
    "            # Log a message or handle the empty DataFrame scenario as needed\n",
    "            msg = \"The query returned an empty DataFrame.\"\n",
    "            logger.error(msg)\n",
    "            raise ValueError(msg)\n",
    "        logger.info(\"Query executed successfully.\")\n",
    "        return df\n",
    "    except ValueError as e: \n",
    "        logger.error(f\"SQL query failed. Error: {e}\")\n",
    "        raise e\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred while querying the database. Error: {e}\")\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b8bb7d",
   "metadata": {},
   "source": [
    "Now when we run the incorrect query again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6cc433f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-26 00:24:15,230 - data_ingestion - INFO - Database engine created successfully.\n",
      "2024-05-26 00:24:15,237 - data_ingestion - ERROR - The query returned an empty DataFrame.\n",
      "2024-05-26 00:24:15,238 - data_ingestion - ERROR - SQL query failed. Error: The query returned an empty DataFrame.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The query returned an empty DataFrame.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 13\u001b[0m\n\u001b[0;32m      3\u001b[0m sql_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124mSELECT *\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124mFROM geographic_features\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124mWHERE Rainfall < 0 \u001b[39m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# The last line won't ever be true, so no results will be returned. \u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m df \u001b[38;5;241m=\u001b[39m query_data(SQL_engine, sql_query)\n\u001b[0;32m     14\u001b[0m df\n",
      "Cell \u001b[1;32mIn[27], line 40\u001b[0m, in \u001b[0;36mquery_data\u001b[1;34m(engine, sql_query)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e: \n\u001b[0;32m     39\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSQL query failed. Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     42\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while querying the database. Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[27], line 35\u001b[0m, in \u001b[0;36mquery_data\u001b[1;34m(engine, sql_query)\u001b[0m\n\u001b[0;32m     33\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe query returned an empty DataFrame.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     34\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(msg)\n\u001b[1;32m---> 35\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m     36\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuery executed successfully.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "\u001b[1;31mValueError\u001b[0m: The query returned an empty DataFrame."
     ]
    }
   ],
   "source": [
    "SQL_engine = create_db_engine('sqlite:///Maji_Ndogo_farm_survey_small.db')\n",
    "\n",
    "sql_query = \"\"\"\n",
    "SELECT *\n",
    "FROM geographic_features\n",
    "LEFT JOIN weather_features USING (Field_ID)\n",
    "LEFT JOIN soil_and_crop_features USING (Field_ID)\n",
    "LEFT JOIN farm_management_features USING (Field_ID)\n",
    "WHERE Rainfall < 0 \n",
    "\"\"\"\n",
    "# The last line won't ever be true, so no results will be returned. \n",
    "\n",
    "df = query_data(SQL_engine, sql_query)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d83421",
   "metadata": {},
   "source": [
    "We get a log of what happened, and we now get an error telling us there is something wrong with the DataFrame, and we are prevented from processing it further."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d867e110",
   "metadata": {},
   "source": [
    "Next up, let's include the CSV data handling. This is the original code: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "31b5eb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_station_df = pd.read_csv(\"https://raw.githubusercontent.com/Explore-AI/Public-Data/master/Maji_Ndogo/Weather_station_data.csv\")\n",
    "weather_station_mapping_df = pd.read_csv(\"https://raw.githubusercontent.com/Explore-AI/Public-Data/master/Maji_Ndogo/Weather_data_field_mapping.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae0f7f6",
   "metadata": {},
   "source": [
    "These two files are imported in the same way, so we can use one function to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f8c8a6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-26 00:24:18,136 - data_ingestion - INFO - CSV file read successfully from the web.\n",
      "2024-05-26 00:24:18,901 - data_ingestion - INFO - CSV file read successfully from the web.\n"
     ]
    }
   ],
   "source": [
    "weather_data_URL = \"https://raw.githubusercontent.com/Explore-AI/Public-Data/master/Maji_Ndogo/Weather_station_data.csv\"\n",
    "weather_mapping_data_URL = \"https://raw.githubusercontent.com/Explore-AI/Public-Data/master/Maji_Ndogo/Weather_data_field_mapping.csv\"\n",
    "\n",
    "\n",
    "def read_from_web_CSV(URL):\n",
    "    try:\n",
    "        df = pd.read_csv(URL)\n",
    "        logger.info(\"CSV file read successfully from the web.\")\n",
    "        return df\n",
    "    except pd.errors.EmptyDataError as e:\n",
    "        logger.error(\"The URL does not point to a valid CSV file. Please check the URL and try again.\")\n",
    "        raise e\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to read CSV from the web. Error: {e}\")\n",
    "        raise e\n",
    "    \n",
    "    \n",
    "weather_df = read_from_web_CSV(weather_data_URL)\n",
    "weather_mapping_data = read_from_web_CSV(weather_mapping_data_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b77cfc",
   "metadata": {},
   "source": [
    "Great! Now our code can connect to a database for the field data, use a query to retrieve data and create a DataFrame. We can also import CSV files from a URL into a DataFrame, and avoid pulling unexpected data. If we put all this code together we have the basic structure of our module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a0462cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sqlalchemy import create_engine, text\n",
    "import logging\n",
    "import pandas as pd\n",
    "\n",
    "# Name our logger so we know that logs from this module come from the data_ingestion module\n",
    "logger = logging.getLogger('data_ingestion')\n",
    "# Set a basic logging message up that prints out a timestamp, the name of our logger, and the message\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "db_path = 'sqlite:///Maji_Ndogo_farm_survey_small.db'\n",
    "\n",
    "sql_query = \"\"\"\n",
    "SELECT *\n",
    "FROM geographic_features\n",
    "LEFT JOIN weather_features USING (Field_ID)\n",
    "LEFT JOIN soil_and_crop_features USING (Field_ID)\n",
    "LEFT JOIN farm_management_features USING (Field_ID)\n",
    "\"\"\"\n",
    "\n",
    "weather_data_URL = \"https://raw.githubusercontent.com/Explore-AI/Public-Data/master/Maji_Ndogo/Weather_station_data.csv\"\n",
    "weather_mapping_data_URL = \"https://raw.githubusercontent.com/Explore-AI/Public-Data/master/Maji_Ndogo/Weather_data_field_mapping.csv\"\n",
    "\n",
    "def create_db_engine(db_path):\n",
    "    try:\n",
    "        engine = create_engine(db_path)\n",
    "        # Test connection\n",
    "        with engine.connect() as conn:\n",
    "            pass\n",
    "        # test if the database engine was created successfully\n",
    "        logger.info(\"Database engine created successfully.\")\n",
    "        return engine # Return the engine object if it all works well\n",
    "    except ImportError: #If we get an ImportError, inform the user SQLAlchemy is not installed\n",
    "        logger.error(\"SQLAlchemy is required to use this function. Please install it first.\")\n",
    "        raise e\n",
    "    except Exception as e:# If we fail to create an engine inform the user\n",
    "        logger.error(f\"Failed to create database engine. Error: {e}\")\n",
    "        raise e\n",
    "    \n",
    "def query_data(engine, sql_query):\n",
    "    try:\n",
    "        with engine.connect() as connection:\n",
    "            df = pd.read_sql_query(text(sql_query), connection)\n",
    "        if df.empty:\n",
    "            # Log a message or handle the empty DataFrame scenario as needed\n",
    "            msg = \"The query returned an empty DataFrame.\"\n",
    "            logger.error(msg)\n",
    "            raise ValueError(msg)\n",
    "        logger.info(\"Query executed successfully.\")\n",
    "        return df\n",
    "    except ValueError as e: \n",
    "        logger.error(f\"SQL query failed. Error: {e}\")\n",
    "        raise e\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred while querying the database. Error: {e}\")\n",
    "        raise e\n",
    "    \n",
    "def read_from_web_CSV(URL):\n",
    "    try:\n",
    "        df = pd.read_csv(URL)\n",
    "        logger.info(\"CSV file read successfully from the web.\")\n",
    "        return df\n",
    "    except pd.errors.EmptyDataError as e:\n",
    "        logger.error(\"The URL does not point to a valid CSV file. Please check the URL and try again.\")\n",
    "        raise e\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to read CSV from the web. Error: {e}\")\n",
    "        raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "39a85194",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-26 00:24:19,670 - data_ingestion - INFO - Database engine created successfully.\n",
      "2024-05-26 00:24:19,778 - data_ingestion - INFO - Query executed successfully.\n",
      "2024-05-26 00:24:20,412 - data_ingestion - INFO - CSV file read successfully from the web.\n",
      "2024-05-26 00:24:21,109 - data_ingestion - INFO - CSV file read successfully from the web.\n"
     ]
    }
   ],
   "source": [
    "# Testing module functions  \n",
    "field_df = query_data(create_db_engine(db_path), sql_query)   \n",
    "weather_df = read_from_web_CSV(weather_data_URL)\n",
    "weather_mapping_df = read_from_web_CSV(weather_mapping_data_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a713ffaa",
   "metadata": {},
   "source": [
    "Once we run this we should get a log telling us that it all worked. \n",
    "\n",
    "Note that there are imports at the top of the cell. When we move this to a module, it needs to import packages like SQL Alchemy and Pandas. \n",
    "\n",
    "Let's do a test to make sure these functions are working well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "977a2cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "field_df: (5654, 18), weather_df: (1843, 2), weather_mapping_df: (5654, 3)\n"
     ]
    }
   ],
   "source": [
    "field_test = field_df.shape\n",
    "weather_test = weather_df.shape\n",
    "weather_mapping_test = weather_mapping_df.shape\n",
    "print(f\"field_df: {field_test}, weather_df: {weather_test}, weather_mapping_df: {weather_mapping_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcc78d4",
   "metadata": {},
   "source": [
    "**Expected outcome:** \n",
    "\n",
    "`field_df: (5654, 18), weather_df: (1843, 2), weather_mapping_df: (5654, 3)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dcd517",
   "metadata": {},
   "source": [
    "Before we go and move this into the `data_ingestion.py` file, we are missing one **crucial** aspect. \n",
    "\n",
    "**Documentation!** We need to add a module docstring and function docstrings. \n",
    "\n",
    "<br>\n",
    "\n",
    "⚙️ **Task:** Create a **module docstring** and **function docstrings** for each function. Refer to your notes and PEP 8 guidelines (also see `PEP 257`) to guide you on what these docstrings should contain. Edit the code below to make these changes. \n",
    "\n",
    ">⚠️ Do not change the logic of this code, only add documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9105b239",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Module: data_ingestion\n",
    "\n",
    "This module provides functions to ingest data from various sources.\n",
    "\n",
    "\"\"\"\n",
    "from sqlalchemy import create_engine, text\n",
    "import logging\n",
    "import pandas as pd\n",
    "# Name our logger so we know that logs from this module come from the data_ingestion module\n",
    "logger = logging.getLogger('data_ingestion')\n",
    "# Set a basic logging message up that prints out a timestamp, the name of our logger, and the message\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "db_path = 'sqlite:///Maji_Ndogo_farm_survey_small.db'\n",
    "\n",
    "sql_query = \"\"\"\n",
    "SELECT *\n",
    "FROM geographic_features\n",
    "LEFT JOIN weather_features USING (Field_ID)\n",
    "LEFT JOIN soil_and_crop_features USING (Field_ID)\n",
    "LEFT JOIN farm_management_features USING (Field_ID)\n",
    "\"\"\"\n",
    "\n",
    "weather_data_URL = \"https://raw.githubusercontent.com/Explore-AI/Public-Data/master/Maji_Ndogo/Weather_station_data.csv\"\n",
    "weather_mapping_data_URL = \"https://raw.githubusercontent.com/Explore-AI/Public-Data/master/Maji_Ndogo/Weather_data_field_mapping.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d8f2e53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "\"\"\"Module: data_ingestion\n",
    "\n",
    "This module provides functions to ingest data from various sources.\n",
    "\n",
    "\"\"\"\n",
    "from sqlalchemy import create_engine, text\n",
    "import logging\n",
    "import pandas as pd\n",
    "\n",
    "# Name our logger so we know that logs from this module come from the data_ingestion module\n",
    "logger = logging.getLogger('data_ingestion')\n",
    "\n",
    "# Set a basic logging message up that prints out a timestamp, the name of our logger, and the message\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def create_db_engine(db_path):\n",
    "    \"\"\"Create a SQLAlchemy database engine.\n",
    "\n",
    "    Args:\n",
    "        db_path (str): The path to the database.\n",
    "\n",
    "    Returns:\n",
    "        sqlalchemy.engine.base.Engine: The SQLAlchemy engine object.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        engine = create_engine(db_path)\n",
    "        # Test connection\n",
    "        with engine.connect() as conn:\n",
    "            pass\n",
    "        # test if the database engine was created successfully\n",
    "        logger.info(\"Database engine created successfully.\")\n",
    "        return engine # Return the engine object if it all works well\n",
    "    except ImportError: #If we get an ImportError, inform the user SQLAlchemy is not installed\n",
    "        logger.error(\"SQLAlchemy is required to use this function. Please install it first.\")\n",
    "        raise e\n",
    "    except Exception as e:# If we fail to create an engine inform the user\n",
    "        logger.error(f\"Failed to create database engine. Error: {e}\")\n",
    "        raise e\n",
    "    \n",
    "def query_data(engine, sql_query):\n",
    "    \"\"\"Execute a SQL query on a database engine and return the result as a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        engine (sqlalchemy.engine.base.Engine): The SQLAlchemy engine object.\n",
    "        sql_query (str): The SQL query to execute.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The result of the SQL query as a DataFrame.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with engine.connect() as connection:\n",
    "            df = pd.read_sql_query(text(sql_query), connection)\n",
    "        if df.empty:\n",
    "            # Log a message or handle the empty DataFrame scenario as needed\n",
    "            msg = \"The query returned an empty DataFrame.\"\n",
    "            logger.error(msg)\n",
    "            raise ValueError(msg)\n",
    "        logger.info(\"Query executed successfully.\")\n",
    "        return df\n",
    "    except ValueError as e: \n",
    "        logger.error(f\"SQL query failed. Error: {e}\")\n",
    "        raise e\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred while querying the database. Error: {e}\")\n",
    "        raise e\n",
    "    \n",
    "def read_from_web_CSV(URL):\n",
    "    \"\"\"Read a CSV file from a web URL and return it as a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        URL (str): The URL of the CSV file.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The CSV file contents as a DataFrame.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(URL)\n",
    "        logger.info(\"CSV file read successfully from the web.\")\n",
    "        return df\n",
    "    except pd.errors.EmptyDataError as e:\n",
    "        logger.error(\"The URL does not point to a valid CSV file. Please check the URL and try again.\")\n",
    "        raise e\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to read CSV from the web. Error: {e}\")\n",
    "        raise e\n",
    "    \n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f0c4fb",
   "metadata": {},
   "source": [
    "Let's test our code to make sure it works before we move on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "27dcc193",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-26 00:24:32,352 - data_ingestion - INFO - Database engine created successfully.\n",
      "2024-05-26 00:24:32,452 - data_ingestion - INFO - Query executed successfully.\n",
      "2024-05-26 00:24:33,166 - data_ingestion - INFO - CSV file read successfully from the web.\n",
      "2024-05-26 00:24:33,879 - data_ingestion - INFO - CSV file read successfully from the web.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "field_df: (5654, 18), weather_df: (1843, 2), weather_mapping_df: (5654, 3)\n"
     ]
    }
   ],
   "source": [
    "# Testing module functions  \n",
    "field_df = query_data(create_db_engine(db_path), sql_query)   \n",
    "weather_df = read_from_web_CSV(weather_data_URL)\n",
    "weather_mapping_df = read_from_web_CSV(weather_mapping_data_URL)\n",
    "\n",
    "field_test = field_df.shape\n",
    "weather_test = weather_df.shape\n",
    "weather_mapping_test = weather_mapping_df.shape\n",
    "print(f\"field_df: {field_test}, weather_df: {weather_test}, weather_mapping_df: {weather_mapping_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6c609b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "26fd094b-0fee-46f1-a4b8-73766813c42b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#  \n",
    "\n",
    "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/ExploreAI_logos/EAI_Blue_Dark.png\"  style=\"width:200px\";/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce7f6f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
